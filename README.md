Thesis: Application of Artificial Intelligence Methods in the Requirements Engineering Management Process
ğŸ”¹ Overview

This repository supports my MSc thesis:
â€œApplication of Artificial Intelligence Methods in the Requirements Engineering Management Process.â€
The research explores how AI techniques â€” particularly NLP, transformer-based models, and graph-based representations â€” can enhance the extraction, classification, and management of requirements.
The core contribution is an end-to-end pipeline that transforms raw elicited requirements into a semantic requirement graph, enabling automation, traceability, and explainability in the Requirements Engineering Management Process (REMP).

ğŸ”¹ End-to-End Process

Input: Raw elicited requirement sentences (unstructured text)
Output: Structured, classified, and explainable requirement graphs (Neo4j)

ğŸ“Œ Pipeline Steps

Preprocessing â€“ text normalization and cleaning.
Requirement Extraction (Dual NER) â€“ spaCy + BERT/RemBERT extract Actor, Goal, Rationale (AGR).
Completeness & Confidence â€“ slot-level evaluation + weighted confidence scoring.
Graph Construction â€“ AGR triplets stored in a Neo4j semantic graph.
Classification â€“ Functional vs Non-Functional; Multi-aspect NFR classification using fine-tuned BERT.
Explainability â€“ SHAP/LIME highlights key tokens influencing classification.
Validation & Feedback Loop â€“ low-confidence cases flagged for manual review.

ğŸ”¹ Datasets Used

PROMISE NFR Dataset â€“ Functional vs Non-Functional requirements.
NoRBERT (PROMISE variant) â€“ Multi-label NFR dimensions.
REMBERT-AGR Dataset â€“ Actor, Goal, Rationale triplets.
Custom Dataset â€“ manually curated requirements for evaluation.

ğŸ”¹ Tools & Frameworks

Python (Google Colab)
spaCy + Transformers (NER & preprocessing)
Hugging Face BERT/RemBERT (fine-tuned models)
Neo4j (semantic graph construction)
SHAP / LIME (explainability layer) 
